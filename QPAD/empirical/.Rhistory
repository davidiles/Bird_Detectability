D_joint = Yobs/offset_joint
D_indep = Yobs/offset_indep
(D_indep-D_joint)/D_joint * 100
(offset_joint - offset_indep)/offset_indep * 100
Yobs <- 5
offset_joint = 2
offset_indep = 1
D_joint = Yobs/offset_joint
D_indep = Yobs/offset_indep
(D_indep-D_joint)/D_joint * 100
(offset_joint - offset_indep)/offset_indep * 100
Yobs <- 0
offset_joint = 2
offset_indep = 1
D_joint = Yobs/offset_joint
D_indep = Yobs/offset_indep
(D_indep-D_joint)/D_joint * 100
(offset_joint - offset_indep)/offset_indep * 100
Yobs <- 0.001
offset_joint = 2
offset_indep = 1
D_joint = Yobs/offset_joint
D_indep = Yobs/offset_indep
(D_indep-D_joint)/D_joint * 100
(offset_joint - offset_indep)/offset_indep * 100
source("C:/Users/david/Documents/1_Work/Bird_Detectability/QPAD/bSims_examples/bSims_movement.R")
install.packages("bbsBayes")
library(bbsBayes)
fetch_bbs_data()
fetch_bbs_data(force=TRUE)
stratified_data <- stratify(by = "bbs_cws")
?prepare_jags_data
sum(seq(5,35))
sum(seq(5,35))/60
library(bbsBayes)
library(readxl)
library(tidyverse)
#fetch_bbs_data(force=TRUE)
setwd("C:/Users/david/Documents/1_Work/trend_analysis")
stratified_data <- stratify(by = "bbs_cws")
# ---------------------------------------------------
# Identify species to consider analyzing
# ---------------------------------------------------
# Load species generation lengths
bird_GL <- read_xlsx("data/Bird2020_TableS4.xlsx")
# Which species are in the generation length dataset?
stratified_data$species_strat$Scientific_Name <- paste0(stratified_data$species_strat$genus," ",stratified_data$species_strat$species)
bird_GL <- subset(bird_GL, Scientific_Name %in% stratified_data$species_strat$Scientific_Name)
# Merge common names
bird_GL <- left_join(bird_GL,stratified_data$species_strat[,c("english","Scientific_Name")]) %>%
rename(CommonName = english)
# Only select species with "long" generation times
species_list <- subset(bird_GL, GenLength >5) #, english %in% c("Blue Jay","American Crow","Turkey Vulture","Great Blue Heron")) %>% as.data.frame()
species_list
# Loop through species, and calculate number of routes per year on which the species was detected
sp_data_summary <- data.frame()
for (sp in species_list$CommonName){
sp_aou <- subset(stratified_data$species_strat, english == sp)$aou %>% as.integer()
sp_dat <- stratified_data$bird_strat %>%
subset(AOU == sp_aou) %>%
subset(Year >= 1980) %>%
group_by(statenum,Route,countrynum,Year) %>%
summarize(sum = sum(SpeciesTotal)) %>%
group_by(statenum,Route,countrynum) %>%
summarize(n_year = length(unique(Year)),
min_year = min(Year),
max_year = max(Year))
# Number of routes where species was observed in at least 10 years, with min_year <= 1980 and max_year >= 2015
sp_dat <- subset(sp_dat, n_year >= 10 & min_year <= 1990 & max_year >= 2020)
sp_data_summary <- rbind(sp_data_summary, data.frame(Species = sp,
nrts = nrow(sp_dat)))
}
# To be included in analysis, species must have been detected on at least 250 routes in at least 10 years
sp_to_analyze <- subset(sp_data_summary, nrts >= 250) %>%
left_join(bird_GL, by = c("Species" = "CommonName"))
# --------------------------------
# Species general properties
# --------------------------------
# Blue Jay: well covered by BBS; large increases
# American Crow: well covered by BBS; relatively stable
# Turkey Vulture: well covered by BBS; massive population increases
# Great Blue Heron: well covered by BBS; population decreases
sp = "Blue Jay"
# ----------------------------------------
# Fit model
# ----------------------------------------
filename <- paste0(sp,".RData")
if (file.exists(filename)){
load(filename)
} else{
trend_matrix <- matrix(NA,nrow=30,ncol=6000) # each row is a trend of different length, cols are samples
for (trend_length in 2:30){
start <- Sys.time()
start_year <- 1990
end_year <- start_year + trend_length
jags_data <- prepare_data(stratified_data,
species_to_run = sp,
min_year = start_year,
max_year = end_year,
model = "firstdiff")
jags_mod <- run_model(jags_data = jags_data,
n_saved_steps = 1000,
n_burnin = 5000,
n_chains = 3,
n_thin = 5,
parallel = TRUE,
parameters_to_save = c("n", "n3", "nu", "B.X", "beta.X", "strata", "sdbeta", "sdX"),
modules = NULL)
# ----------------------------------------
# Convergence
# ----------------------------------------
jags_mod$n.eff #shows the effective sample size for each monitored parameter
jags_mod$Rhat # shows the Rhat values for each monitored parameter
# ----------------------------------------
# Extract trend estimates
# ----------------------------------------
indices <- generate_indices(jags_mod = jags_mod,
jags_data = jags_data,
regions = c("continental"))
indx <- indices$samples$continental_Continental # indices for each year
t2 <- ncol(indx)
trend_manual <- 100*((indx[,t2]/indx[,1])^(1/(t2-1))-1)
trend_matrix[trend_length,] <- trend_manual
end <- Sys.time()
print(trend_length)
print(end-start)
# ----------------------------------------
# Summarize trend estimates
# ----------------------------------------
GenLength <- subset(sp_to_analyze, Species == sp)$GenLength
ThreeGenerations <- ceiling(GenLength*3)
trend_summary <- trend_matrix %>%
reshape2::melt() %>%
na.omit() %>%
rename(trend_length = Var1,
samp = Var2,
trend = value) %>%
group_by(trend_length) %>%
summarize(trend_q50 = quantile(trend,0.5),
trend_q025 = quantile(trend,0.05),
trend_q975 = quantile(trend,0.95),
p_increase = mean(trend>0))
trend_summary_plot <- ggplot(trend_summary, aes(x = trend_length, y = trend_q50, ymin = trend_q025, ymax = trend_q975)) +
geom_hline(yintercept = 0, col = "gray50")+
geom_vline(xintercept = ThreeGenerations, col = "gray50", linetype = 2)+
geom_errorbar(width=0, col = "dodgerblue")+
geom_point(col = "dodgerblue")+
theme_bw()+
ylab("Trend estimate\n\n% change per year")+
xlab("Trend length\n(years since 1990)")+
ggtitle(sp)+
coord_cartesian(ylim=c(-5,5),
xlim=c(1,30))+
scale_y_continuous(breaks = seq(-100,100,1))
print(trend_summary_plot)
}
#save(trend_matrix, file = filename)
}
# ----------------------------------------
# Summarize trend estimates
# ----------------------------------------
GenLength <- subset(sp_to_analyze, Species == sp)$GenLength
ThreeGenerations <- ceiling(GenLength*3)
trend_summary <- trend_matrix %>%
reshape2::melt() %>%
na.omit() %>%
rename(trend_length = Var1,
samp = Var2,
trend = value) %>%
group_by(trend_length) %>%
summarize(trend_q50 = quantile(trend,0.5),
trend_q025 = quantile(trend,0.05),
trend_q975 = quantile(trend,0.95),
p_increase = mean(trend>0))
trend_summary_plot <- ggplot(trend_summary, aes(x = trend_length, y = trend_q50, ymin = trend_q025, ymax = trend_q975)) +
geom_hline(yintercept = 0, col = "gray50")+
geom_vline(xintercept = ThreeGenerations, col = "gray50", linetype = 2)+
geom_errorbar(width=0, col = "dodgerblue")+
geom_point(col = "dodgerblue")+
theme_bw()+
ylab("Trend estimate\n\n% change per year")+
xlab("Trend length\n(years since 1990)")+
ggtitle(sp)+
coord_cartesian(ylim=c(-5,5),
xlim=c(1,30))+
scale_y_continuous(breaks = seq(-100,100,1))
print(trend_summary_plot)
library(tidyverse)
library(reshape2)
library(jagsUI)
library(ggpubr)
rm(list=ls())
phi = 0.2
tau = 1
est_df <- data.frame()
library(tidyverse) # For general data manipulation
library(mefa4)     # some specific data handling functions
library(ggrepel)
library(detect)
# Install/load David Hope's C++ version of the 'joint model'
##### remotes::install_github("dhope/CmultiJoint.dev")
library(CmultiJoint.dev)
setwd("C:/Users/david/Documents/1_Work/Bird_Detectability/QPAD/empirical")
`%!in%` <- Negate(`%in%`)
# -------------------------------------------------------------
# Read data
# -------------------------------------------------------------
dat <- read.csv("aru-join-table_AUG 22.csv")
dat$SurveyType <- dat$SurveyType %>%
as.factor() %>%
relevel("HUM")
# REMOVE SPECIES that commonly do flyovers or are otherwise inappropriate for pointcounts
aa <- table(dat$SPECIES)
SPP <- names(aa[aa >= 15])
SPP <- SPP[!(SPP %in% c("AMCR","AMGO","BCFR","BLJA","CANG","COLO","COGO","COME","CORA","EVGR","FRGU","GRAJ","UNKN","RESQ","WOSP","WWCR","WISN","SACR","PISI","UNBI","LEYE","GRYE","WOFR","UNKN"))]
dat<-dat[dat$SPECIES %in% SPP,]
nrow(dat)
nmin <- 15
# Remove cases that lack time interval
dat <- subset(dat, TimeInterval != "")
table(dat$TimeInterval)
# Time interval types
time_ints_all <- unique(dat$TimeInterval)
tint_type1 <- c("0-3 min","3-5 min","5-10 min") # Broken into 3,5,10
tint_type2 <- time_ints_all[(time_ints_all %!in% tint_type1)] # Broken into 1 minute bins
# Recode time bins
tint_replace <- data.frame(TimeInterval = unique(dat$TimeInterval),
time_type = c(2,2,2,2,2,2,2,2,2,2,1,1,1),
time_bin = c(1,2,10,7,9,5,8,3,4,6,1,3,2)) %>%
arrange(time_type,time_bin)
dat <- left_join(dat,tint_replace)
# Recode distance bins
dat$dist_bin <- NA
dat$dist_bin[dat$DISTANCE == "ARU"] <- 1
dat$dist_bin[dat$DISTANCE == "0-49 m"] <- 1
dat$dist_bin[dat$DISTANCE == "50-100 m"] <- 2
dat$dist_bin[dat$DISTANCE == ">100 m"] <- 3
# Maximum number of distance bins in the dataset
mdbin <- max(dat$dist_bin)
# Maximum number of time bins in the dataset
mtbin <- max(dat$time_bin)
# Separate Human and ARU data
dat_HUM <- subset(dat, SurveyType == "HUM")
dat_ARU <- subset(dat, SurveyType == "ARU")
# -------------------------------------------------------------
# Format into arrays for use with cmulti_joint_fit
# -------------------------------------------------------------
PKEY_vec <- unique(dat$PKEY)
nsurvey <- length(unique(dat$PKEY))
rarray_HUM <- rarray_ARU <- array(NA,dim=c(nsurvey,mdbin))
tarray_HUM <- tarray_ARU <- array(NA,dim=c(nsurvey,mtbin))
# -------------------------------------------------
# Loop through species and construct time and distance arrays
# -------------------------------------------------
calculate_offsets
###################################################################################################################################
library(tidyverse) # For general data manipulation
library(mefa4)     # some specific data handling functions
library(ggrepel)
library(detect)
# Install/load David Hope's C++ version of the 'joint model'
##### remotes::install_github("dhope/CmultiJoint.dev")
library(CmultiJoint.dev)
setwd("C:/Users/david/Documents/1_Work/Bird_Detectability/QPAD/empirical")
`%!in%` <- Negate(`%in%`)
# -------------------------------------------------------------
# Read data
# -------------------------------------------------------------
dat <- read.csv("aru-join-table_AUG 22.csv")
dat$SurveyType <- dat$SurveyType %>%
as.factor() %>%
relevel("HUM")
# REMOVE SPECIES that commonly do flyovers or are otherwise inappropriate for pointcounts
aa <- table(dat$SPECIES)
SPP <- names(aa[aa >= 15])
SPP <- SPP[!(SPP %in% c("AMCR","AMGO","BCFR","BLJA","CANG","COLO","COGO","COME","CORA","EVGR","FRGU","GRAJ","UNKN","RESQ","WOSP","WWCR","WISN","SACR","PISI","UNBI","LEYE","GRYE","WOFR","UNKN"))]
dat<-dat[dat$SPECIES %in% SPP,]
nrow(dat)
nmin <- 15
# Remove cases that lack time interval
dat <- subset(dat, TimeInterval != "")
table(dat$TimeInterval)
# Time interval types
time_ints_all <- unique(dat$TimeInterval)
tint_type1 <- c("0-3 min","3-5 min","5-10 min") # Broken into 3,5,10
tint_type2 <- time_ints_all[(time_ints_all %!in% tint_type1)] # Broken into 1 minute bins
# Recode time bins
tint_replace <- data.frame(TimeInterval = unique(dat$TimeInterval),
time_type = c(2,2,2,2,2,2,2,2,2,2,1,1,1),
time_bin = c(1,2,10,7,9,5,8,3,4,6,1,3,2)) %>%
arrange(time_type,time_bin)
dat <- left_join(dat,tint_replace)
# Recode distance bins
dat$dist_bin <- NA
dat$dist_bin[dat$DISTANCE == "ARU"] <- 1
dat$dist_bin[dat$DISTANCE == "0-49 m"] <- 1
dat$dist_bin[dat$DISTANCE == "50-100 m"] <- 2
dat$dist_bin[dat$DISTANCE == ">100 m"] <- 3
# Maximum number of distance bins in the dataset
mdbin <- max(dat$dist_bin)
# Maximum number of time bins in the dataset
mtbin <- max(dat$time_bin)
# Separate Human and ARU data
dat_HUM <- subset(dat, SurveyType == "HUM")
dat_ARU <- subset(dat, SurveyType == "ARU")
# -------------------------------------------------------------
# Format into arrays for use with cmulti_joint_fit
# -------------------------------------------------------------
PKEY_vec <- unique(dat$PKEY)
nsurvey <- length(unique(dat$PKEY))
rarray_HUM <- rarray_ARU <- array(NA,dim=c(nsurvey,mdbin))
tarray_HUM <- tarray_ARU <- array(NA,dim=c(nsurvey,mtbin))
# -------------------------------------------------
# Loop through species and construct time and distance arrays
# -------------------------------------------------
for (k in 1:nsurvey){
# Human data
kdat_HUM <- subset(dat_HUM, PKEY == PKEY_vec[k])
# ARU
kdat_ARU <- subset(dat_ARU, PKEY == PKEY_vec[k])
# Must have detected at least one species with both surveys (removes surveys "2007-157-12_1" and "06-171-07_1")
if (nrow(kdat_HUM)==0 | nrow(kdat_ARU)==0) print(PKEY_vec[k])
# -------------------------------------
# Human data
# -------------------------------------
rarray_HUM[k,]<- c(0.5,1,Inf)
# Determine type of time binning
if (kdat_HUM$TimeInterval[1] %in% tint_type1){
tarray_HUM[k,] <- c(3,5,10,rep(NA,7))
} else{ tarray_HUM[k,] <- seq(1,10)}
# -------------------------------------
# ARU data
# -------------------------------------
rarray_ARU[k,]<- c(Inf,NA,NA)
# Determine type of time binning
if (kdat_ARU$TimeInterval[1] %in% tint_type1){
tarray_ARU[k,] <- c(3,5,10,rep(NA,7))
} else{ tarray_ARU[k,] <- seq(1,10)}
}
# -------------------------------------------------
# Format counts for each species
# Analyze using a variety of methods
# -------------------------------------------------
species_vec <- unique(dat$SPECIES)
estimate_df <- data.frame(Species = species_vec,
nHUM = NA,
nARU = NA,
# Only fitting to human data
tau_HUM = NA,
# Pooling data for tau
tau_joined_null = NA,
# Modeling tau separately for HUM and ARU
tau_joined_HUM = NA,
tau_joined_ARU = NA,
phi_HUM = NA,
phi_joined_null = NA,
phi_joined = NA,
offset_HUM = NA,
offset_joined_null = NA,
offset_joined_HUM = NA,
offset_joined_ARU = NA
)
for (sp in 1:nrow(estimate_df)){
sp_code = estimate_df$Species[sp]
print(sp_code)
# Total number of birds detected by humans
nHUM <- sum(subset(dat_HUM, SPECIES == sp_code)$Count)
nARU <- sum(subset(dat_ARU, SPECIES == sp_code)$Count)
estimate_df$nHUM[sp] <- nHUM
estimate_df$nARU[sp] <- nARU
if (nHUM < 100 | nARU < 100){next}
# ---------------------------------
# Prepare Yarrays for analysis
# ---------------------------------
Yarray_HUM <- Yarray_ARU <- array(NA,dim=c(nsurvey,mdbin,mtbin))
for (k in 1:nsurvey){
# Human data
kdat_HUM <- subset(dat_HUM, PKEY == PKEY_vec[k])
# ARU
kdat_ARU <- subset(dat_ARU, PKEY == PKEY_vec[k])
# Human data
nrint_HUM <- length(na.omit(rarray_HUM[k,]))
ntint_HUM <- length(na.omit(tarray_HUM[k,]))
Yarray_HUM[k,1:nrint_HUM,1:ntint_HUM] <- 0
kdat_HUM <- subset(dat_HUM, PKEY == PKEY_vec[k] & SPECIES == sp_code)
if (nrow(kdat_HUM)>0){
for (i in 1:nrow(kdat_HUM)){
Yarray_HUM[k,kdat_HUM$dist_bin[i],kdat_HUM$time_bin[i]] <- kdat_HUM$Count[i]
}
}
# ARU data
nrint_ARU <- length(na.omit(rarray_ARU[k,]))
ntint_ARU <- length(na.omit(tarray_ARU[k,]))
Yarray_ARU[k,1:nrint_ARU,1:ntint_ARU] <- 0
kdat_ARU <- subset(dat_ARU, PKEY == PKEY_vec[k] & SPECIES == sp_code)
if (nrow(kdat_ARU)>0){
for (i in 1:nrow(kdat_ARU)){
Yarray_ARU[k,kdat_ARU$dist_bin[i],kdat_ARU$time_bin[i]] <- kdat_ARU$Count[i]
}
}
}
# -----------------------------
# Combine human and ARU data
# -----------------------------
Yarray_joined <- array(NA,dim=c(dim(Yarray_HUM)[1]*2,dim(Yarray_HUM)[2:3]))
rarray_joined <- array(NA,dim=c(dim(rarray_HUM)[1]*2,dim(rarray_HUM)[2]))
tarray_joined <- array(NA,dim=c(dim(tarray_HUM)[1]*2,dim(tarray_HUM)[2]))
Yarray_joined[1:dim(Yarray_HUM)[1],,] <- Yarray_HUM
Yarray_joined[(dim(Yarray_HUM)[1]+1):dim(Yarray_joined)[1],,] <- Yarray_ARU
rarray_joined[1:dim(rarray_HUM)[1],] <- rarray_HUM
rarray_joined[(dim(rarray_HUM)[1]+1):dim(rarray_joined)[1],] <- rarray_ARU
tarray_joined[1:dim(tarray_HUM)[1],] <- tarray_HUM
tarray_joined[(dim(tarray_HUM)[1]+1):dim(tarray_joined)[1],] <- tarray_ARU
# Specify design matrix for "sensor type" which will affect tau
sensor <- c(rep("HUM",nsurvey),rep("ARU",nsurvey))
X_sensor <- model.matrix(~sensor)
# -----------------------------
# Conduct joint analysis on human data
# -----------------------------
# Fit model
start <- Sys.time()
Yarray <- Yarray_HUM
rarray <- rarray_HUM
tarray <- tarray_HUM
fit_HUM <- cmulti_fit_joint(Yarray,
rarray,
tarray,
X1 = NULL, # Design matrix for tau
X2 = NULL  # Design matrix for phi
)
end <- Sys.time()
print(end-start)
estimate_df$tau_HUM[sp] <- exp(fit_HUM$coefficients[1])
estimate_df$phi_HUM[sp] <- exp(fit_HUM$coefficients[2])
# Calculate offset for an unlimited distance, 10-minute survey
offset_Inf10_HUM <- calculate_offsets(fit_HUM,
rarray = array(Inf,dim=c(1,1)),
tarray = array(10,dim=c(1,1)),
X1 = NULL,
X2 = NULL)
estimate_df$offset_HUM[sp] <- offset_Inf10_HUM
# -----------------------------
# Combine human and ARU data
# -----------------------------
Yarray_joined <- array(NA,dim=c(dim(Yarray_HUM)[1]*2,dim(Yarray_HUM)[2:3]))
rarray_joined <- array(NA,dim=c(dim(rarray_HUM)[1]*2,dim(rarray_HUM)[2]))
tarray_joined <- array(NA,dim=c(dim(tarray_HUM)[1]*2,dim(tarray_HUM)[2]))
Yarray_joined[1:dim(Yarray_HUM)[1],,] <- Yarray_HUM
Yarray_joined[(dim(Yarray_HUM)[1]+1):dim(Yarray_joined)[1],,] <- Yarray_ARU
rarray_joined[1:dim(rarray_HUM)[1],] <- rarray_HUM
rarray_joined[(dim(rarray_HUM)[1]+1):dim(rarray_joined)[1],] <- rarray_ARU
tarray_joined[1:dim(tarray_HUM)[1],] <- tarray_HUM
tarray_joined[(dim(tarray_HUM)[1]+1):dim(tarray_joined)[1],] <- tarray_ARU
# -----------------------------
# Conduct joint analysis when including ARU data
# -----------------------------
# Fit model
start <- Sys.time()
Yarray <- Yarray_joined
rarray <- rarray_joined
tarray <- tarray_joined
fit_joined <- cmulti_fit_joint(Yarray,
rarray,
tarray,
X1 = NULL, # Design matrix for tau
X2 = NULL  # Design matrix for phi
)
end <- Sys.time()
print(end-start)
estimate_df$tau_joined_null[sp] <- exp(fit_joined$coefficients[1])
estimate_df$phi_joined_null[sp] <- exp(fit_joined$coefficients[2])
# Calculate offset for an unlimited distance, 10-minute survey
offset_Inf10_joined_null <- calculate_offsets(fit_joined,
rarray = array(Inf,dim=c(1,1)),
tarray = array(10,dim=c(1,1)),
X1 = NULL,
X2 = NULL)
estimate_df$offset_joined_null[sp] <- offset_Inf10_joined_null
# ----------------------------------------------
# Fit model that assumes sensor affects tau
# ----------------------------------------------
start <- Sys.time()
Yarray <- Yarray_joined
rarray <- rarray_joined
tarray <- tarray_joined
fit_joined_1 <- cmulti_fit_joint(Yarray,
rarray,
tarray,
X1 = X_sensor, # Design matrix for tau
X2 = NULL  # Design matrix for phi
)
end <- Sys.time()
print(end-start)
# Calculate offset for an unlimited distance, 10-minute survey
sensor <- c("HUM","ARU")
X_sensor_pred <- model.matrix(~sensor)
# Estimates of tau under human and ARU surveys
tau_est <- exp(X_sensor_pred %*% fit_joined_1$coefficients[-1])*100
estimate_df$tau_joined_HUM[sp] <- tau_est[1]
estimate_df$tau_joined_ARU[sp] <- tau_est[2]
# Estimates of phi under human and ARU surveys
phi_est <- exp(fit_joined_1$coefficients[3])
estimate_df$phi_joined[sp] <- phi_est
offset_Inf10_joined <- calculate_offsets(fit_joined_1,
rarray = array(Inf,dim=c(2,1)),
tarray = array(10,dim=c(2,1)),
X1 = X_sensor_pred,
X2 = NULL)
estimate_df$offset_Inf10_joined_HUM[sp] <- offset_Inf10_joined[1]
estimate_df$offset_Inf10_joined_ARU[sp] <- offset_Inf10_joined[2]
print(sp)
}
